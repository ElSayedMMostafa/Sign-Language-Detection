{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#this script works with OpenCV4\n",
    "import cv2\n",
    "from helpers import *\n",
    "from keras import models\n",
    "import numpy as np \n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from datetime import datetime\n",
    "from keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Video, tracking and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y','Z', 'del', 'nothing', 'space' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Loading our pretrained model\n",
    "model = models.load_model('models/model_large_asl_mobilenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = ['']*30 # Used for voting selection\n",
    "prediction_per_frame = [] # Used for saving voted decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begginning detection\n",
      "Start Tracking\n",
      "[290, 541, 210, 525]\n",
      "[198, 479, 115, 417]\n",
      "[274, 615, 216, 555]\n",
      "[288, 615, 171, 499]\n",
      "[202, 543, 230, 534]\n",
      "[144, 403, 184, 457]\n",
      "[116, 513, 132, 583]\n",
      "[134, 543, 140, 516]\n"
     ]
    }
   ],
   "source": [
    "begin_time = datetime.now()\n",
    "\n",
    "#Read Video\n",
    "cap = cv2.VideoCapture('demos/Sayed_Demo3.mp4')\n",
    "\n",
    "#Get Region of Interest\n",
    "success, img = cap.read()\n",
    "roi = segment_hand(img,0)\n",
    "\n",
    "#Define Boundry Box\n",
    "bbox = (roi[2], roi[0], roi[3]-roi[2], roi[1]-roi[0])\n",
    "\n",
    "#Initialize Tracker\n",
    "#tracker = cv2.TrackerCSRT_create()\n",
    "tracker = cv2.TrackerMOSSE_create()\n",
    "print('Begginning detection')\n",
    "success = tracker.init(img, bbox)\n",
    "print('Start Tracking')\n",
    "hands= []\n",
    "count = 0\n",
    "prediction = '0'\n",
    "while True:\n",
    "    #Get current Frame\n",
    "    success1, img = cap.read()\n",
    "    \n",
    "    ## No more frames in the video\n",
    "    if not success1:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    \n",
    "    #count frames \n",
    "    count +=1\n",
    "    n_frame_update = 60 #number of frames after which run the detection and reset the tracker\n",
    "\n",
    "    #Run detection every n_frame_update\n",
    "    if count%n_frame_update == 0:\n",
    "\n",
    "        #Run detection \n",
    "        roi = segment_hand(img,0)\n",
    "        print(roi)\n",
    "        bbox = (roi[2], roi[0], roi[3]-roi[2], roi[1]-roi[0])\n",
    "        \n",
    "        #delete old tracker and create a new one\n",
    "        del tracker\n",
    "        tracker = cv2.TrackerMOSSE_create()\n",
    "        success = tracker.init(img, bbox)\n",
    "\n",
    "        #print on screen \n",
    "        cv2.putText(img, \"Detecting\", (100,20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,255,0),2)\n",
    "    \n",
    "    # Track otherwise\n",
    "    else:\n",
    "        #Update tracker\n",
    "        success, bbox = tracker.update(img)\n",
    "    \n",
    "    #if Tracker succeded\n",
    "    if success:\n",
    "        #Draw Boundry Box\n",
    "        start_point = (int(bbox[0]),int(bbox[1]))\n",
    "        end_point = (int(bbox[0]+bbox[2]),int(bbox[1]+bbox[3]))\n",
    "        cv2.rectangle(img, start_point, end_point, (255,0,0), 2)\n",
    "        \n",
    "        #Prediction\n",
    "        # Remove exceptions from tracker\n",
    "        if start_point[1] < 0:\n",
    "            prediction_per_frame.append(prediction)\n",
    "            continue\n",
    "        # Crop the hand according to tracker and detector results    \n",
    "        hand = img[start_point[1]:end_point[1],start_point[0]:end_point[0]]\n",
    "        \n",
    "        #hands.append(hand)\n",
    "        \n",
    "        # Resize Images to suit the model\n",
    "        test = preprocess_input(hand)\n",
    "        test = resize(test, (224,224,3))\n",
    "        test = np.array(test , dtype='float32')\n",
    "        test = test.reshape(1,224,224,3)\n",
    "        # Predict\n",
    "        pred_label = model.predict(test)\n",
    "        pred_label = np.argmax(pred_label,axis=1)\n",
    "        pred = class_names[int(pred_label[0])]\n",
    "        \n",
    "        #Vote\n",
    "        vote.pop(0)\n",
    "        voting = sum([pred == vot for vot in vote])\n",
    "        vote.append(pred)\n",
    "        # If the current prediction matches at least 3 of the last five update prediction\n",
    "        if voting >= 7 or count <7:\n",
    "            prediction = pred\n",
    "            \n",
    "            \n",
    "        # Append in the Decision list anyway    \n",
    "        prediction_per_frame.append(prediction)\n",
    "        \n",
    "        # Print Decision on preview \n",
    "        cv2.putText(img, prediction , (300,50), cv2.FONT_HERSHEY_SIMPLEX, 1.5,(0,0,255),3)\n",
    "\n",
    "    else:\n",
    "        #If Tracker Failed\n",
    "        cv2.putText(img, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "    \n",
    "    #Show image\n",
    "    cv2.imshow(\"Tracking\", img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q') or k == 27:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "time_taken = datetime.now() - begin_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.465116279069768"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps = len(prediction_per_frame)/time_taken.seconds\n",
    "fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix for Videos\n",
    "def compute_confusion(video: int, prediction_per_frame):\n",
    "    labels = []\n",
    "    fps = len(prediction_per_frame)\n",
    "    ## Sayed_Demo2\n",
    "    if video == 1:\n",
    "        for i in range(fps):\n",
    "            if i >0.7*fps:\n",
    "                labels.append('C')\n",
    "            elif i >=0.23*fps:\n",
    "                labels.append('A')                              \n",
    "            else:\n",
    "                labels.append('O')\n",
    "    ## Sayed_Demo3\n",
    "    if video == 2:\n",
    "        for i in range(fps):\n",
    "            if i >fps*0.69:\n",
    "                labels.append('C')\n",
    "            elif i >=fps*0.46:\n",
    "                labels.append('O')                              \n",
    "            else:\n",
    "                labels.append('A')\n",
    "    ## Asmar-Demo3\n",
    "    if video == 3:\n",
    "        for i in range(fps):\n",
    "            if i>0.65:\n",
    "                labels.append('O')\n",
    "            elif i>=0.43:\n",
    "                labels.append('C')\n",
    "            elif i>=0.24:\n",
    "                labels.append('R')\n",
    "            else:\n",
    "                labels.append('A')\n",
    "    ## Demo_CV1\n",
    "    if video == 4:\n",
    "        for i in range(fps):\n",
    "            if i>0.68:\n",
    "                labels.append('C')\n",
    "            elif i>=0.49:\n",
    "                labels.append('R')\n",
    "            elif i>=167:\n",
    "                labels.append('Z')\n",
    "            else:\n",
    "                labels.append('A')\n",
    "    # Salma_Demo1\n",
    "    if video == 5:\n",
    "        for i in range(fps):\n",
    "            if i >fps*0.88:\n",
    "                labels.append('A')\n",
    "            elif i >=fps*0.77:\n",
    "                labels.append('V')\n",
    "            elif i >=fps*0.65:\n",
    "                labels.append('U') \n",
    "            elif i >=fps*0.4:\n",
    "                labels.append('C')  \n",
    "            elif i >=fps*0.33:\n",
    "                labels.append('B')\n",
    "            else:\n",
    "                labels.append('A')\n",
    "    # Asmaa_Demo\n",
    "    if video == 6:\n",
    "        for i in range(fps):\n",
    "            if i>0.84*fps:\n",
    "                labels.append('N')\n",
    "            elif i>=0.6*fps:\n",
    "                labels.append('I')\n",
    "            elif i>=0.41*fps:\n",
    "                labels.append('B')\n",
    "            elif i>=0.22*fps:\n",
    "                labels.append('G')\n",
    "            else:\n",
    "                labels.append('B')\n",
    "    # Sayed_Demo4\n",
    "    if video == 7:\n",
    "        for i in range(fps):\n",
    "            if i>0.68*fps:\n",
    "                labels.append('I')\n",
    "            elif i>=0.53*fps:\n",
    "                labels.append('V')\n",
    "            elif i>=0.2167*fps:\n",
    "                labels.append('N')\n",
    "            else:\n",
    "                labels.append('W')\n",
    "    return labels, confusion_matrix(labels, prediction_per_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155,   1,   0,   1,  36,   0,   2,   1,  51],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 111,   0,  19,  36,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 24,   0,   0,   0,  85,  14,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, conf = compute_confusion(2, prediction_per_frame)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.48507462686567"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels, prediction_per_frame)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_list = [labels[i] == prediction_per_frame[i] for i in range(len(labels))]\n",
    "c = 0\n",
    "correct = [0]\n",
    "for i in range(len(labels)):\n",
    "    if truth_list[i]:\n",
    "        c +=1\n",
    "    else:\n",
    "        correct.append(c)\n",
    "        c=0\n",
    "        \n",
    "max_correct_frames = max(correct)\n",
    "max_correct_frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
